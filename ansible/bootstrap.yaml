---
- name: create rhos-17-1 standalone vm
  hosts: localhost
  connection: local
  vars:
    # change these 3 folders to your deployment
    project_dir: '/home/someuser'
    # folder with source images
    images_dir: '/images/source'
    # folder with generated vm disks
    guest_dir: '/images/guests'
    os: 'rhel9.2'
    os_image: 'rhel-9.2-x86_64-kvm.qcow2'
    ssh_pubkey: '{{ lookup("file", "{{ project_dir }}/.ssh/id_ed25519.pub") }}'
    ssh_privatekey: '{{ lookup("file", "{{ project_dir }}/.ssh/id_ed25519") }}'
    subdomain: home.lan
    root_password: 'redhat'
    public_network: 'virbr1'
    deploy_targets:
      - name: rhos-17-1
        machine: pc-q35-8.2
        vcpus: 10
        memory: 32768
        root_disk_size: 128G
        network:
          - "{{ public_network }}"
        # This runs virt-customize on an os disk image before cloud-init
        # and works around vendor defaults that can have implications for
        # cloud-init configuration.  For example the rhel9 cloud image sets
        # net.ifnames=0 at boot which will alter the enumeration of devices
        # that network_config can manipulate.
        #
        # Generally speaking it is better to use cloud-init to perform guest
        # customiation but there are circumstances like this where you need
        # a pre-first-time-boot step.
        #
        # if this variable is not defined, it will be skipped during bootstrap
        pre_boot_os_customization: |
          if grep -q net.ifnames=0 /etc/default/grub;
          then
            sed -i 's/net.ifnames=0//g' /etc/default/grub;
            for f in grub2 grub2-efi;
            do
              grub2-mkconfig -o $(readlink -f /etc/$f.cfg);
            done
          fi
        network_config:
          version: 2
          renderer: NetworkManager
          ethernets:
            enp1s0:
              addresses:
                - 10.10.1.5/24
              routes:
                - to: 0.0.0.0/0
                  via: 10.10.1.1
              nameservers:
                addresses:
                  - 10.10.0.1
        extra_disk:
          - name: rhos-17-1-swap.img
            type: raw
            size: 32G
          - name: rhos-17-1-ceph-data.qcow2
            type: qcow2
            size: 128G
            options: "-o compression_type=zstd"
        user_data:
          # groups:
          #  sudo:
          #    - stack
          users:
            - name: root
              lock_passwd: false
              hashed_passwd: "{{ root_password | password_hash('sha512') }}"
            - name: stack
              ssh_authorized_keys:
                - "{{ ssh_pubkey }}"
              sudo:  'ALL=(ALL) NOPASSWD: ALL'
              shell: /bin/bash
          write_files:
            - path: /etc/hosts
              content: |
                10.10.1.5         rhos-17-1.home.lan rhos-17-1
              append: true
          runcmd:
            - parted /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_rhos-17-1-swap mklabel gpt mkpart primary linux-swap 0% 100%
            - partprobe /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_rhos-17-1-swap
            - udevadm settle
            - mkswap /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_rhos-17-1-swap-part1
            - echo -e "[Swap]\nWhat=/dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_rhos-17-1-swap-part1\n[Install]\nWantedBy=swap.target" | sudo tee /etc/systemd/system/dev-disk-by\\x2did-scsi\\x2d0QEMU_QEMU_HARDDISK_rhos\\x2d17\\x2d1\\x2dswap\\x2dpart1.swap
            - systemctl daemon-reload
            - systemctl enable --now dev-disk-by\\x2did-scsi\\x2d0QEMU_QEMU_HARDDISK_rhos\\x2d17\\x2d1\\x2dswap\\x2dpart1.swap
            # cloud-init in rhel8 and rhel9 appear to be based on v21 which doesnt support  write_files.defer :(
            - chown -R stack:stack /home/stack
            

  tasks:
    - name: cleanup tasks
      tags: clean
      block:
      - name: clean up old instances
        shell:
          cmd: |
            virsh destroy {{ item.name }}
            virsh undefine --nvram {{ item.name }}
        with_items: '{{ deploy_targets }}'
        ignore_errors: yes
        become: true
        no_log: true    

      - name: clean up old images and cloud-init data
        file:
          path: '{{ guest_dir }}/{{ item.name }}.qcow2'
          state: absent
        with_items: "{{ deploy_targets }}"
        no_log: true
        become: true
      - file:
          path: '{{ images_dir }}/{{ item.name }}/'
          state: absent
        with_items: "{{ deploy_targets }}"
        no_log: true
        become: true
      - file:
          path: '{{ guest_dir }}/{{ item.1.name }}'
          state: absent
        loop: "{{ deploy_targets | subelements('extra_disk') }}"
        loop_control:
          label: "{{ item.0.name }}"
        no_log: true
        become: true

    - name: initialize cloud-init folders
      file:
        path: '{{ images_dir }}/{{ item.name }}'
        state: directory
      with_items: '{{ deploy_targets }}'
      become: true
      no_log: true
      
    - name: create linked clone from base image for each deploy_target
      command: qemu-img create -b {{ images_dir }}/{{ os_image }} -f qcow2 -F qcow2 -o {{ item.1.compression | default("compression_type=zstd") }} {{ guest_dir }}/{{ item.name }}.qcow2 {{ item.root_disk_size }}
      with_items: "{{ deploy_targets }}"
      become: true
      no_log: true

    - name: create volumes defined in extra_disk
      command: qemu-img create -f {{ item.1.type }} {{ item.1.options | default("") }} {{ guest_dir }}/{{ item.1.name }} {{ item.1.size }}
      loop: "{{ deploy_targets | subelements('extra_disk') }}"
      loop_control:
        label: "{{ item.0.name }}"
      no_log: true
      become: true

    - name: create cloud-init metadata
      copy:
        content: '{{ metadata | default({}) | combine({ "instance-id": fqdn, "local-hostname": fqdn  }) | to_nice_yaml }}'
        dest: '{{ images_dir }}/{{ item.name }}/meta-data'
      vars:
        metadata: {}
        fqdn: '{{ item.name }}.{{ subdomain }}'
        ni: ''
      with_items: '{{ deploy_targets }}'
      no_log: true
      become: true

    # when using nocloud datasource in-line nework configuration
    # can only be performed from meta-data or creating a new file 
    # called network-config
    - name: create cloud-init network-config
      copy:
        content: '{{ item.network_config }}'
        dest: '{{ images_dir }}/{{ item.name }}/network-config'
      with_items: '{{ deploy_targets }}'
      no_log: true
      become: true

    - name: create cloud-init user-data
      copy:
        content: '{{ item.user_data | to_nice_yaml }}'
        dest: '{{ images_dir }}/{{ item.name }}/user-data'
      with_items: '{{ deploy_targets }}'
      no_log: true      
      become: true
    - lineinfile:
        path: '{{ images_dir }}/{{ item.name }}/user-data'
        insertbefore: BOF
        line: "#cloud-config"
      with_items: '{{ deploy_targets }}'
      no_log: true
      become: true

    - name: Create cloud-init configuration image
      command: |
        genisoimage -V cidata -r -J \
                    -output {{ images_dir }}/{{ item.name }}/{{ item.name }}-cidata.iso \
                   {{ images_dir }}/{{ item.name }}/user-data \
                   {{ images_dir }}/{{ item.name }}/meta-data \
                   {{ images_dir }}/{{ item.name }}/network-config

      with_items: '{{ deploy_targets }}'
      no_log: true
      become: true

    - name: Upload and modify grub configuration in VM image
      command: |
        virt-customize -a {{ guest_dir }}/{{ item.name }}.qcow2 \
        --run-command "{{ item.pre_boot_os_customization }}"
      with_items: '{{ deploy_targets }}'
      when: item.pre_boot_os_customization is defined and item.pre_boot_os_customization | length > 0
      register: virt_customize
      no_log: true
      async: 180
      poll: 0

    - async_status: jid={{ item.ansible_job_id }}
      register: virt_customize_jobs
      until: virt_customize_jobs.finished
      retries: 300
      with_items: '{{ virt_customize.results }}'
      become: true
      no_log: true

    - name: create the vm
      command: |
        virt-install
        --machine {{ item.machine | default("q35") }}
        --boot uefi
        --name={{ item.name }}
        --ram={{ item.memory }}
        --vcpus={{ item.vcpus }}
        --controller type=scsi,model=virtio-scsi
        --import
        {#
          virtio-scsi disks are unstable since changes related to this patch:

            https://github.com/libguestfs/libguestfs/commit/bca9b94fc593771b3801b09b95e477f160517909

          We need to use wwn / serial to identify the disk meant for SWAP and CEPH
        #}
        --disk path={{ guest_dir }}/{{ item.name }}.qcow2,bus=scsi,cache=none,discard=unmap,boot.order=1,wwn=rotation_rate=1,wwn={{ "0xDEADBEEF" ~ '%08X' % 0 }},serial={{ item.name }}
        {% for disk in item.extra_disk %}
          --disk {{ guest_dir}}/{{ disk.name }},bus=scsi,discard=unmap,rotation_rate=1,cache=none,wwn={{ "0xDEADBEEF" ~ '%08X' % (loop.index0 + 1) }},serial={{ disk.name.split('.')[0] }}
        {% endfor %}
        --disk path={{ images_dir }}/{{ item.name }}/{{ item.name }}-cidata.iso,device=cdrom
        --os-variant {{ os }}
        {% for nic in item.network %}
          --network bridge={{ nic }},model=virtio
        {% endfor %}
        --rng /dev/urandom
        --graphics none
        --serial pty
        --console pty,target_type=serial
        --noautoconsole
      become: true
      async: 180
      poll: 0
      register: virt_install
      with_items: '{{ deploy_targets }}'
      no_log: true
    - async_status: jid={{ item.ansible_job_id }}
      register: virt_install_jobs
      until: virt_install_jobs.finished
      retries: 300
      with_items: '{{ virt_install.results }}'
      become: true
      no_log: true
  
